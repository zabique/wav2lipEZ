{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wav2Lip TenDeepfake eng.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sE22UQtQ9YYi"
      },
      "source": [
        "# **Welcome to Wav2Lip colab mod by Ten Deepfake**\n",
        "\n",
        "# **There is no need for colab pro to use it.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cA_SNxHxT0P"
      },
      "source": [
        "# **Check GPU**\n",
        "\n",
        "*   Google Colab can provide you with one of Tesla graphics cards: K80, T4, P4, P100 and V100\n",
        "*   Here you can check the model of GPU before using Wav2Lip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTiJ1TJKNj_J",
        "cellView": "form"
      },
      "source": [
        "#@title Start\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XCqT2ITN-In"
      },
      "source": [
        "# **Mount your Google drive**\n",
        "\n",
        "1. Connect to your google drive to store Wave2lip model files.\n",
        "2. Ctrl+v auth key and hit ENTER\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qciH4PsUazL_",
        "cellView": "form"
      },
      "source": [
        "#@title Start\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJ5taGmPcWV-"
      },
      "source": [
        "# **Get the code and models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3LihClHbUd3",
        "cellView": "form"
      },
      "source": [
        "#@title Clone Wav2Lip github repo\n",
        "!git clone https://github.com/Rudrabha/Wav2Lip.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekFHoZJS26tt"
      },
      "source": [
        "**You need to download at least one wav2lip model and put it in root of your google drive inside of /Wav2Lip/ folder.**\n",
        "1. [Wav2Lip\tHighly accurate lip-sync](https://iiitaphyd-my.sharepoint.com/:u:/g/personal/radrabha_m_research_iiit_ac_in/Eb3LEzbfuKlJiR600lQWRxgBIY27JZg80f7V9jtMfbNDaQ?e=TBFBVW)\n",
        "2. [Wav2Lip + GAN\tSlightly inferior lip-sync, but better visual quality](https://iiitaphyd-my.sharepoint.com/:u:/g/personal/radrabha_m_research_iiit_ac_in/EdjI7bZlgApMqsVoEUUXpLsBxqXbn5z8VTmoxp55YNDcIA?e=n9ljGW)\n",
        "\n",
        "**If none of the links work, go to official wav2lip github to find them.**\n",
        "[HERE](https://github.com/Rudrabha/Wav2Lip#training-on-datasets-other-than-lrs2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjzMPy_Sb0AI",
        "cellView": "form"
      },
      "source": [
        "#@title Copy wav2lip_gan.pth model\n",
        "!cp -ri \"/content/gdrive/MyDrive/Wav2lip/wav2lip_gan.pth\" /content/Wav2Lip/checkpoints/"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "RO0-LWzar-u-"
      },
      "source": [
        "#@title Copy wav2lip.pth model\n",
        "!cp -ri \"/content/gdrive/MyDrive/Wav2lip/wav2lip.pth\" /content/Wav2Lip/checkpoints/"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ooh28vw-Uvd3",
        "cellView": "form"
      },
      "source": [
        "#@title Uninstall tensorflow - Confirm with y [ enter ]\n",
        "!pip uninstall tensorflow tensorflow-gpu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49dCYlLdcK2D",
        "cellView": "form"
      },
      "source": [
        "#@title Requirements.txt\n",
        "!cd Wav2Lip && pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ey_bN4M6X_95",
        "cellView": "form"
      },
      "source": [
        "#@title Download Face detection model\n",
        "!wget \"https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\" -O \"Wav2Lip/face_detection/detection/sfd/s3fd.pth\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgjaWJFs8B38"
      },
      "source": [
        "# **Quick guide**\n",
        "1. Create video file input_video.mp4\n",
        "2. Create audio file input_audio.wav\n",
        "3. Both files have to be exact same length\n",
        "4. Target face in the input_video.mp4, must be in ALL videoframes (So no black or blurry frames etc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdIQfY2Kswcb"
      },
      "source": [
        "# **Now lets try!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "vsphzJawLF-f"
      },
      "source": [
        "#@title Upload input_video.mp4 & input_audio.wav files\n",
        "%cd sample_data/\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR5utmDMcSZY",
        "cellView": "form"
      },
      "source": [
        "#@title Create Wav2Lip video (using wav2lip_gan.pth) GAN\n",
        "!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"/content/sample_data/input_video.mp4\" --audio \"/content/sample_data/input_audio.wav\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "WxbzXZvLliiA"
      },
      "source": [
        "#@title Play result video -  50% scaling\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "mp4 = open('/content/Wav2Lip/results/result_voice.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(f\"\"\"\n",
        "<video width=\"50%\" height=\"50%\" controls>\n",
        "      <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "</video>\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kt-krsEbz5j",
        "cellView": "form"
      },
      "source": [
        "#@title Download Result.mp4 to your computer\n",
        "from google.colab import files\n",
        "files.download('/content/Wav2Lip/results/result_voice.mp4') \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7zgfrQqbKom"
      },
      "source": [
        "# **Variations to try**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "-4PqQrDcphU4"
      },
      "source": [
        "#@title 1.Create Wav2Lip video (using wav2lip.pth) NON-GAN\n",
        "!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip.pth --face \"/content/sample_data/input_video.mp4\" --audio \"/content/sample_data/input_audio.wav\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xw0xFtZ2bsx8",
        "cellView": "form"
      },
      "source": [
        "#@title 2.Use resize_factor to reduce the video resolution, as there is a change you might get better results for lower resolution videos. Why? Because the model was trained on low resolution faces.\n",
        "!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"/content/sample_data/input_video.mp4\" --audio \"/content/sample_data/input_audio.wav\" --resize_factor 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45XW4SZAzIz5",
        "cellView": "form"
      },
      "source": [
        "#@title 3.Use more padding to include the chin region (u can manually edit pads dimensions viewing and changing the code)\n",
        "!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"/content/sample_data/input_video.mp4\" --audio \"/content/sample_data/input_audio.wav\" --pads 0 20 0 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "X1Z0zRdZR5BZ"
      },
      "source": [
        "#@title Play result video -  50% scaling\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "mp4 = open('/content/Wav2Lip/results/result_voice.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(f\"\"\"\n",
        "<video width=\"50%\" height=\"50%\" controls>\n",
        "      <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "</video>\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "gfXFOpAmR_dh"
      },
      "source": [
        "#@title Download Result.mp4 to your computer\n",
        "from google.colab import files\n",
        "files.download('/content/Wav2Lip/results/result_voice.mp4') \n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}